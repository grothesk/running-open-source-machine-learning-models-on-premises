apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "resnet-18"
spec:
  predictor:
    minReplicas: 1
    maxReplicas: 3
    serviceAccountName: sa
    pytorch: # use torchserve as model serving runtime
      storageUri: "s3://models/torchserve/resnet-18/1.0" # load the model from here
